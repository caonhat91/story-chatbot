@startuml LLM_RAG_Architecture
title LLM-based RAG System - Layered Architecture

sequenceDiagram
    participant Client
    participant FastAPI
    participant RAGChain
    participant Retriever
    participant Chroma
    participant Gemini
    participant LangSmith

    Client->>FastAPI: POST /chat/stream (question, sessionId)
    FastAPI->>RAGChain: astream(question, sessionId)
    RAGChain->>LangSmith: trace start
    RAGChain->>Retriever: retrieve(query, user_id)
    Retriever->>Chroma: similarity search
    Chroma-->>Retriever: documents
    Retriever-->>RAGChain: context
    RAGChain->>Gemini: prompt + context
    Gemini-->>FastAPI: stream tokens
    FastAPI-->>Client: SSE tokens
    RAGChain->>LangSmith: trace end

@enduml
